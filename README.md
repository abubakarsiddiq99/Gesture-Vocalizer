# Gesture-Vocalizer


This comprehensive project presents the design, development, and implementation of a Finger Gesture Controlled Display System utilizing the Arduino Uno microcontroller platform to autonomously recognize human hand gestures. The system integrates five analog flex sensors to detect the bend angle of individual fingers and translates these physical movements into predefined textual outputs displayed on a screen. A 16x2 LCD display interfaced provides continuous visual feedback, showing the recognized gesture text (e.g., "Hi," "Bye," "I need water"). The primary objective is to create a low-cost, real-time communication interface, particularly useful for silent or non-verbal interaction. The implementation strictly follows procedural programming principles in C/C++ using the Arduino IDE. The prototype was rigorously tested in a simulated environment using Tinkercad, confirming stable sensor readings, accurate mapping of bend angles, and reliable text display responses. The logic ensures that a unique message is displayed only when a specific finger is bent beyond a defined threshold. Future scalability is supported through optional integration of voice synthesis modules to transform the text into spoken words, enabling a true "vocalizer" function. This project demonstrates a practical fusion of hardware and software engineering, promoting accessible communication through affordable automation


Effective communication is crucial, and technology can bridge gaps for non-verbal individuals or in environments requiring silent signaling. Traditional communication aids can be complex or expensive. This project addresses these challenges by introducing a Gesture Vocalizer System that leverages modern microcontroller technology to interpret hand gestures in real-time. The Arduino Uno serves as the central processing unit, ideal for educational and prototyping applications in procedural programming courses. The system uses five flex sensors worn on the fingers as input sensors, the Arduino for processing the bend data, and an LCD display for output. Real-world applications span from communication aids and gaming interfaces to educational tools and small-scale robotics control. The primary objectives are to design a functional system that continuously monitors the bend state of all five fingers, activates a corresponding display message when a unique single-finger gesture is detected, and operates independently. Beyond technical execution, the project aims to reinforce core concepts in circuit design, analog-to-digital conversion, conditional logic, and modular coding practices.
